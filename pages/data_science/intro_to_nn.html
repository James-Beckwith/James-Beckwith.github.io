<!DOCTYPE html>
<html lang="en">

<head>
    <!-- following line is needed so that plotly can display negative numbers in plots correctly -->
    <meta charset="utf-8">
    <!-- Plotly.js -->
    <!-- the local version requires the use of Plotly.newPlot -->
    <script src="../../scripts/plotly-2.18.2.min.js"></script>
    <!-- <script src="https://cdn.plot.ly/plotly-2.18.2.min.js"></script> -->
    <!-- <link rel="stylesheet" href="http://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/default.min.css">
    <script src="http://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script> -->
    <!-- use prism JS instead, looks nicer, especially the tomorrow dark theme -->
    <link rel="stylesheet" type="text/css" href="../../vendors/css/ionicons.min.css">
    <link rel="stylesheet" type="text/css" href="../../resources/css/style2.css">
    <link rel="stylesheet" type="text/css" href="../../vendors/css/prism.css">
    <link rel="stylesheet" type="text/css" href="../../resources/css/technical_page.css">
    <link rel="stylesheet" type="text/css" href="../../resources/css/queries.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <script>
        MathJax = {
            tex: { inlineMath: [['$in', '$in'], ['\\(', '\\)']] }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>

<body>
    <nav>
        <div class="row">
            <!-- ul is an unordered list which should contain li list elements -->
            <ul class="main-nav js--main-nav">
                <li><a href="../../index.html">Home</a></li>
                <!-- TODO maybe thinking about changing Home to a home icon instead?-->
                <li><a herf="../../about.html">About</a></li>
                <li><a herf="#">Education</a></li>
                <li><a herf="#">Resources</a></li>
            </ul>
            <a class="mobile-nav-icon js--nav-icon"><i class="ion-navicon-round"></i></a>
        </div>
    </nav>

    <div class="main-container">

        <h1 class="knowledge_h1">Page under construction</h1>

        <p class="knowledge_p">
            A neural network is a network of neurons which is designed to minimize some loss function. This function
            typically takes the form of some accuracy between some input feature(s) from a training dataset and some
            target label(s). But it could also be that the network (or agent) is trained to minimize some loss (or
            maximize some reward) function by performing tasks. However it happens, the network takes some input
            feature(s), maps them to some output(s) and then a loss is defined based on these outputs (more commonly
            called predictions in many contexts) and the desired outputs.
            <!-- TODO - finish this section -->
        </p>

        <h2 class="knowledge_h2">What is a neuron?</h2>
        <p class="knowledge_p">
            A neuron is a basic building block a neural network. A neural network, at a basic level, is a network of
            neurons which process some input feature(s), potentially with some other information, to produce a result.
            The result is numerical but this could be interpreted as the probability that the output belongs to a
            certain class, mapped back to a word embedding (more on that in the natural language processing section) or
            interpreted as an image. But what <i>is</i> a neuron?
        </p>
        <p class="knowledge_p">
            A neuron, can be any basic building block that can be defined mathematically. Not everything that can be
            defined will be useful as a neuron in a neural network though and some standard useful forms of neurons have
            been discovered and used over the years since they were first described by McCulloch and Pitts in 1943 (<a
                href="https://link.springer.com/article/10.1007/BF02478259">link</a>).
        </p>
        <p class="knowledge_p">
            One of the most simple form of a neuron is one with a weight matrix, $in W$in, an additive bias, $in b$in,
            and an activation function, $in \textit{g}$in. The cross-product of any input feature vector with the weight
            matrix is formed, the additive bias added, and then this result is passed through the activation function
            (more on activation functions later as there are numerous commonly used functions with different uses).
        </p>

        <img src="../../resources/myImgs/ds/basic_neuron.png" alt="A diagram of a basic neuron" class="knowledge_img">

        <p class="knowledge_p">
            Mathematically, a neuron is represented by:
        </p>
        <p class="knowledge_eq">
            $$\theta(X) = g\left(W^{T}X + b\right)$$
        </p>

        <p class="knowledge_p">
            The weight matrix, $in W$in, has dimensionality equal to the number of input features by the number of
            expected output dimensions, which could be 1 or could be many. The bias term, $in b$in, is a single value
            that is added.
        </p>

        <p class="knowledge_p">
            These neurons can be combined into layers, connected to one-another in linear or cyclical manners, and in
            some instance be much more complicated than is shown here. The entire collection of neurons is referred to
            as the network, whose job it is to map the input features to an expected value or class. Which neurons are
            used and how they are arranged and connected is referred to as the neural network architecture. These neural
            networks have to be trained to produce the mapping between input features and output labels.
        </p>

        <h2 class="knowledge_h2">How to train a neural network</h2>

        <p class="knowledge_p">
            Certain neural network architectures might have their own unique learning processes or workflows but a
            basic, generic workflow for training a neural network is the following:
        </p>

        <pre class="knowledge_algorithm">Initialize the weights
while a stopping metric is not met:
    Pass the input features through the network to form a prediction
    Form the current loss between the predicted output and the true labels using the chosen loss function
    Back propagate this loss through the network to update the weights and biases using the chosen optimizer</pre>

        <!-- TODO - put a simple example in tensorflow to bring the reader directly into "doing something" -->

        <p class="knowledge_p">
            Note that iterative nature of the learning process, it typically takes many iterations to move from a
            network with an initial set weights and biases to one that can predict the value or class that you want.
            There are three key parts to this generic workflow beyond the iterative nature:
            <!-- TODO - indent ordered lists inside p tags -->
        <ol>
            <li>Loss Function</li>
            <li>Optimizer</li>
            <li>Stopping metric</li>
        </ol>
        We'll go through each of these in turn to describe what they are used for, but we will go into loss functions
        and
        optimizers in their own dedicated pages.
        </p>

        <h2 class="knowledge_h2">Loss Function</h2>
        <p class="knowledge_p">
            The loss function is what is used to determine how well the current network can map the input features to
            the target label(s) for the training data set. It is also typically the starting point for back-propagating
            any errors through the network to update the weights, biases, and any other network parameters so that the
            network can perform better at it's job.
        </p>
        <p class="knowledge_p">
            There are a lot of different loss functions, each of which have their pros and cons and some are better
            suited for certain network architectures and end-goals, for instance are you trying train a classification
            model, a regression model, a reinforcement learning model etc.
            <!-- TODO - put in a link to the tensorflow page for loss functions -->
        </p>

        <h2 class="knowledge_h2">Optimizer</h2>
        <p class="knowledge_p">
            Now that you know how well you're model is performing thanks to the loss function we can now use this
            information to update the network. But how exactly do we do this? This is the role of the optimizer. The
            optimizer is a certain algorithm that informs you of how to take you're loss function and propagate this
            back through the network to update it to perform better next time.
            <!-- TODO - finish this section and put link to tensorflow optimizers -->
        </p>

        <h2 class="knowledge_h2">Stopping metrics in neural network training</h2>
        <!-- TODO - link to tensorflow stopping criterion? -->
        <p class="knowledge_p">
            We don't want to be training our neural network indefinitely, after a while the training won't yield any
            improvement in the model and could even eventually make the model worse. So, to optimize the training not
            only for accuracy but also time and compute resources (which equate to money inevitably) we need to know
            when to stop our training. This is the role of some rule or metric that we implement to determine when to
            stop our iterative learning. These can be as simple as setting the number of iterations or more complicated
            metrics based on statistics of the performance of the current network predictions on slices of the training
            or test data sets. Some common training stopping metrics are outlined below but this is not an exhaustive
            list by any means:
        </p>

        <h3>Number of Iterations</h3>

        <p class="knowledge_p">
            Most machine learning algorithms learn iteratively. They don't produce a result immediately in one
            calculation but gradually refine the weights, biases, and other parameters in their network in order to
            lower the loss function. The number of these iterations can be set and used a stopping criterion for the
            learning. This is typically done at the start of an experiment when we might be testing different
            architectures or feature engineering routines.
        </p>

        <h3>Loss function threshold</h3>

        <p class="knowledge_p">
            The loss function is what is used to determine how well the current network can map the input features to
            the target label(s) for the training data set. It is also typically the starting point for back-propagating
            any errors through the network to update the weights, biases, and any other network parameters so that the
            network can perform better at it's job. However, if there is no error, the loss function is zero, then there
            is nothing to back-propagate, no update to be made and continuing without making any other changes would be
            futile. Having a loss function value of zero is only really possible on toy datasets without any noise or
            errors, but a low loss function value could be met. When the loss is small, the update to the network is
            also necessarily small and this could mean a negligible increase in test set accuracy and further training
            of the network would not be cost effective. It makes sense then to impose a stopping criterion for a certain
            level of loss function, i.e. when the loss function is below a certain value then stop training. This level
            would represent an acceptable loss function value given the context of the problem.
        </p>

        <h3>Resource Constraint</h3>

        <p class="knowledge_p">
            This is more valid for cloud deployments of solutions but could also used for local deployments too. For
            cloud deployments we may want to limit the spend on training, either because we are in a test phase or
            because of time or monetary constraints. Like "number of iterations" this stopping criteria isn't a function
            of the network or it's performance but of the resources we have available to train the network. Two of the
            key limiting factors in training large neural networks is time and money. These networks require large
            amounts of compute power to train, which is costly, and take a long time to train, which is again costly.
            One can partially trade-off time for cost by using potentially slower compute resources but only if the
            model can still be trained on these cheaper resources, most large models require a large amount of RAM to
            train. Typically a time bound training regime is just a simple alternative to the number of iterations
            stopping criterion and budgetary constraints can be imposed in many cloud platforms.
        </p>

    </div>


    <div class="license">
        <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License"
                style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a><br />This
        work is
        licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons
            Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
    </div>
</body>

<!-- use this to run the code syntax highlighting in highlight.js -->
<!-- <script>hljs.highlightAll();</script> -->
<!-- use prism JS instead, looks nicer, especially the tomorrow dark theme -->
<script src="../../scripts/prism.js"></script>

</html>