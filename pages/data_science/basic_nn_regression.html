<!DOCTYPE html>
<html lang="en">

<head>
    <!-- following line is needed so that plotly can display negative numbers in plots correctly -->
    <meta charset="utf-8">
    <!-- Plotly.js -->
    <!-- the local version requires the use of Plotly.newPlot -->
    <script src="../../scripts/plotly-2.18.2.min.js"></script>
    <!-- <script src="https://cdn.plot.ly/plotly-2.18.2.min.js"></script> -->
    <!-- <link rel="stylesheet" href="http://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/default.min.css">
    <script src="http://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/highlight.min.js"></script> -->
    <!-- use prism JS instead, looks nicer, especially the tomorrow dark theme -->
    <link rel="stylesheet" type="text/css" href="../../vendors/css/ionicons.min.css">
    <link rel="stylesheet" type="text/css" href="../../resources/css/style2.css">
    <link rel="stylesheet" type="text/css" href="../../vendors/css/prism.css">
    <link rel="stylesheet" type="text/css" href="../../resources/css/technical_page.css">
    <link rel="stylesheet" type="text/css" href="../../resources/css/queries.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <script>
        MathJax = {
            tex: { inlineMath: [['$in', '$in'], ['\\(', '\\)']] }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>

<body>
    <nav>
        <div class="row">
            <!-- ul is an unordered list which should contain li list elements -->
            <ul class="main-nav js--main-nav">
                <li><a href="../../index.html">Home</a></li>
                <!-- TODO maybe thinking about changing Home to a home icon instead?-->
                <li><a herf="../../about.html">About</a></li>
                <li><a herf="#">Education</a></li>
                <li><a herf="#">Resources</a></li>
            </ul>
            <a class="mobile-nav-icon js--nav-icon"><i class="ion-navicon-round"></i></a>
        </div>
    </nav>

    <div class="main-container">

        <h1 class="knowledge_h1">A linear regression example</h1>

        <p class="knowledge_p">In this section there is a brief example of solving the same problem that we solve in the
            case of inverse theory but from the perspective of using a machine learning package and a single neuron
            neural network. See here for reference of how the problem is solved from an inverse theory perspective:
            <a href="../inverse_theory/inverse_force_to_linear.html">Simple mathematical tricks to force a linear
                problem</a>
        </p>

        <p class="knowledge_p">
            Although this is a basic neural network, it will highlight the main components of creating and training a
            typical neural network:
        <ol>
            <li>Data input and test/train split creation</li>
            <li>network architecture</li>
            <li>A loss function</li>
            <li>A optimization routine</li>
            <li>Training</li>
            <li>Displaying training results</li>
        </ol>
        </p>

        <h2 class="knowledge_h2">First, import the necessary libraries</h2>

        <pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# Make NumPy printouts easier to read.
np.set_printoptions(precision=3, suppress=True)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from sklearn import datasets
from sklearn.model_selection import train_test_split</code></pre>

        <h2 class="knowledge_h2">1. Data input and test/train split creation</h2>
        <p class="knowledge_p">
            We'll load a toy dataset from sci-kit learn which has several toy datasets to use. We'll
            use the diabetes dataset which has 442 examples of 10 features with a separate target value. More
            information can be found <a
                href="https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset">here</a>. We'll also
            use the train_test_split function from sci-kit learn to make our train and test datasets
        </p>

        <pre><code class="language-python">
# load the dataset
diabetes = datasets.load_diabetes()
features = diabetes['data']
target = diabetes['target']

# create the train/test split
train_feature, test_feature, train_target, test_target = train_test_split(
     features, target, test_size=0.05, random_state=42)</code></pre>

        <p class="knowledge_p">
            Here we have split the data into train and test datasets using the <i>train_test_split
                function</i> from sklearn.model_selection. We also use a fixed random state so that the training and
            test splits are consistent when we re-run the script
        </p>

        <h2 class="knowledge_h2">Network Architecture</h2>

        <p class="knowledge_p">
            Training a model with <i>tf.keras</i> typically starts by defining the model
            architecture. Here, we use a <i>tf.keras.Sequential</i> model, which <a
                href="https://www.tensorflow.org/guide/keras/sequential_model">represents a sequence of steps</a>. We
            will be training a linear regression model to attempt to map between the input data and the target feature
            using a fully connected layer (<i>tf.keras.layers.Dense</i>) with a linear pass through activation function.
            If we don't specify an activation function in the creation of the fully connected layer
            (<i>layers.Dense</i>), then a linear ($ing(x)=x$in) activation is used. The number of inputs can either be
            set by the <i>input_shape</i> argument, or automatically when the model is run for the first time. Note,
            however, that without defining the input shape we can't show a summary of the model (as the input shape will
            still be unknown to the model until we run data through it).
        </p>

        <pre><code class="language-python">linear_model = tf.keras.Sequential([
    layers.Dense(units=1, input_shape=[10]),
])

# call the summary method of the model to show a summary of the model that we have created
linear_model.summary()
</code></pre>

        <pre><p class="knowledge_pyprint">
            Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_7 (Dense)             (None, 1)                 11        
                                                                 
=================================================================
Total params: 11
Trainable params: 11
Non-trainable params: 0
_________________________________________________________________
        </p></pre>

        <p class="knowledge_p">
            Once we have built the model, we configure the training procedure using the Keras <i>Model.compile</i>
            method. The most important arguments to compile are the <i>loss</i> and the <i>optimizer</i>, since these
            define the loss function to be optimized which serves as a measure of accuracy for predicted outputs from
            the model (<i>mean_absolute_error</i>) and how we should optimize the model based on the outputs of this
            loss function (using the </i>tf.keras.optimizers.Adam</i> optimizer in this instance). We also specify a
            hyper-parameter here for the optimizer in terms of the learning rate, which we'll discuss in the optimizers
            <a href="optimizers.html">topic</a>. This, for the time being is a choice that has been made using prior
            knowledge of what
            works. Hyper-parameter optimization is topic in it's own right and will be covered in a different <a
                href="hyperparameter_optimization.html">topic</a> too.
        </p>

        <pre><code class="language-python">linear_model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.2),
            loss='mean_absolute_error')</code></pre>

        <h2 class="knowledge_h2">Training</h2>

        <p class="knowledge_p">
            Once the model has been built and the training routine defined in the <i>compile</i> method then we can
            execute training using the <i>fit</i> method of our Keras model. Another hyper-parameter of note here is the
            number of epochs. This is set manually here, but can also be optimized using early stopping criteria. We
            store the output of the training in the <i>history</i> variable for further
        </p>

        <pre><code class="language-python">history = linear_model.fit(
    train_feature,
    train_target,
    epochs=100,
    # Suppress logging.
    verbose=0,
    # Calculate validation results on 25% of the training data.
    validation_split = 0.25)</code></pre>

        <h2 class="knowledge_h2">visualization of training metrics</h2>

        <p class="knowledge_p">
            Now that the training has finished we can visualize the model's training progress using the metrics stored in the <i>history</i> object:
        </p>

        <pre><code class="language-python">def plot_loss(history):
    plt.plot(history.history['loss'], label='loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.xlabel('Epoch')
    plt.ylabel('Error')
    plt.legend()
    plt.grid(True)

plot_loss(history)</code></pre>

        <img src="../../resources/myImgs/ds/basic_nn_regression_accuracy_plot.png" alt="A plot of the evolution of the training and validation set accuracy over the training iterations." class="knowledge_img">


        <div class="license">
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img
                    alt="Creative Commons License" style="border-width:0"
                    src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a><br />This
            work is
            licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons
                Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
        </div>


</body>

<!-- use this to run the code syntax highlighting in highlight.js -->
<!-- <script>hljs.highlightAll();</script> -->
<!-- use prism JS instead, looks nicer, especially the tomorrow dark theme -->
<script src="../../scripts/prism.js"></script>

</html>